{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sobre gradient boosting \n",
    "\n",
    "* ref. alg. gradient boosting:  https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html\n",
    "\n",
    "Los parámetros clave a optimizar son:\n",
    "\n",
    "1. `n_estimators`: el número de weak learners (árboles) utilizados.\n",
    "   \n",
    "2. `max_depth`: controla la profundidad de cada árbol.\n",
    "   \n",
    "3. `learning_rate`: hiperparámetro entre 0 y 1, que controla overfitting por medio del método *shringkage* (método de regularización. Parámetro que controla la contribución de cada árbol al aprendizaje. La forma adecuada de utilización es setear learning rate a un valor bajo, < 0.1, y controlar `n_estimators` por *early_stopping*.)\n",
    "\n",
    "4. `subsample`: permite controlar la proporción de datos con el que es entrenado un árbol individual. Por default es `1` pero si se parametriza < 1 los árboles se construyen con data aleatoria. Esto ayuda a disminuir la varianza y aumentar sesgo. \n",
    "\n",
    "Parámetros para el early stopping:\n",
    "\n",
    "1. `validation_fraction`: permite especificar una fracción de datos para utilizarlo en el early stopping. Si después de `n_iter_no_change` en `validation_fraction` no mejora `loss_function`, entonces para el proceso.\n",
    "\n",
    "2. `n_iter_no_change`: número de iteraciones a considerar en el boosting después del cual se aplica early stopping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Trained imputers.\n",
      "> Applied imputers.\n",
      "> Trained encoders.\n",
      "> Applied encoders.\n",
      "> Applied imputers.\n",
      "> Applied encoders.\n",
      "X_train saved in: /home/walter/Documents/personal_projects/new-titan/data/processed/X_train.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from ipynb.fs.full.n01preprocessing import load_obj\n",
    "from ipynb.fs.full.n01preprocessing import save_obj\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project\n",
    "workdir = '/home/walter/Documents/personal_projects/new-titan'\n",
    "exp_prefix = 'notebooks/experiments/exp_04'\n",
    "data_prefix = 'data'\n",
    "chk_prefix = 'checkpoint'\n",
    "\n",
    "# Params\n",
    "target = 'Survived'\n",
    "features = ['Sex', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked', 'Name', 'Ticket']\n",
    "idx = 'Passengerid'\n",
    "\n",
    "# Paths \n",
    "data_train_path = os.path.join(workdir, data_prefix, 'raw/train.csv')\n",
    "\n",
    "dict_path = os.path.join(workdir, exp_prefix, chk_prefix, 'train_dict.pkl')\n",
    "\n",
    "# Text Replacement\n",
    "app_origin = ['Mr',\n",
    " 'Mrs',\n",
    " 'Miss',\n",
    " 'Master',\n",
    " 'Don',\n",
    " 'Rev',\n",
    " 'Dr',\n",
    " 'Mme',\n",
    " 'Ms',\n",
    " 'Major',\n",
    " 'Mrs. Martin (Elizabeth L',\n",
    " 'Lady',\n",
    " 'Sir',\n",
    " 'Mlle',\n",
    " 'Col',\n",
    " 'Capt',\n",
    " 'the Countess',\n",
    " 'Jonkheer',\n",
    " 'other']\n",
    "\n",
    "replacements = ['Mr', 'Mrs', 'Miss', 'Master', 'Mr', 'Rev', 'Dr', 'Mrs', 'Mrs', 'other',\n",
    " 'Mrs', 'Miss', 'Mr', 'Miss', 'other', \n",
    " 'other', 'other', 'other', 'other']\n",
    "\n",
    "replace_app = dict(zip(app_origin, replacements))\n",
    "\n",
    "# ALGO PARS FOR TUNNING\n",
    "loss_function = ['log_loss'] # función objetivo a optimizar \n",
    "learning_rate = [0.01, 0.03, 0.05, 0.1]\n",
    "n_estimators = [50, 100, 300, 500]\n",
    "max_depth = [2,3,4,5,6]\n",
    "subsample = [0.6, 0.8, 1]\n",
    "validation_fraction = [0.2]\n",
    "n_iter_no_change = [5]\n",
    "\n",
    "# TUNNING CONTROL\n",
    "cv = 5\n",
    "n_iter = 100\n",
    "score = 'accuracy'\n",
    "\n",
    "# SETUP\n",
    "params = {\n",
    "'loss': loss_function,\n",
    "'learning_rate': learning_rate, \n",
    "'n_estimators': n_estimators,\n",
    "'max_depth': max_depth,\n",
    "'subsample': subsample,\n",
    "'validation_fraction': validation_fraction,\n",
    "'n_iter_no_change': n_iter_no_change\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(prefix):\n",
    "    X_train = np.genfromtxt(os.path.join(prefix, 'data_train', 'X_train.csv'), delimiter=',')\n",
    "    y_train = np.genfromtxt(os.path.join(prefix, 'data_train', 'y_train.csv'), delimiter=',').astype('int')\n",
    "    label_train = np.genfromtxt(os.path.join(prefix, 'data_train', 'label_train.csv'), delimiter=',')\n",
    "    X_test = np.genfromtxt(os.path.join(prefix, 'data_test', 'X_test.csv'), delimiter=',')\n",
    "    y_test = np.genfromtxt(os.path.join(prefix, 'data_test', 'y_test.csv'), delimiter=',').astype('int')\n",
    "    label_test = np.genfromtxt(os.path.join(prefix, 'data_test', 'label_test.csv'), delimiter=',')\n",
    "\n",
    "    return X_train, y_train, label_train, X_test, y_test, label_test\n",
    "\n",
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results[\"rank_test_score\"] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\n",
    "                \"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                    results[\"mean_test_score\"][candidate],\n",
    "                    results[\"std_test_score\"][candidate],\n",
    "                )\n",
    "            )\n",
    "            print(\"Parameters: {0}\".format(results[\"params\"][candidate]))\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier()\n",
      "(801, 20)\n"
     ]
    }
   ],
   "source": [
    "# load\n",
    "model = load_obj(os.path.join(workdir, exp_prefix, 'artifacts', 'selected_model.pkl'))\n",
    "X, y, label, _, _, _ = load_data(os.path.join(workdir, data_prefix, 'processed'))\n",
    "print(model)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tunning took 55.40 seconds for 100 candidate parameter settings.\n",
      "###\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.831 (std: 0.033)\n",
      "Parameters: {'validation_fraction': 0.2, 'subsample': 1, 'n_iter_no_change': 5, 'n_estimators': 100, 'max_depth': 3, 'loss': 'log_loss', 'learning_rate': 0.03}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.829 (std: 0.043)\n",
      "Parameters: {'validation_fraction': 0.2, 'subsample': 1, 'n_iter_no_change': 5, 'n_estimators': 500, 'max_depth': 3, 'loss': 'log_loss', 'learning_rate': 0.05}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.828 (std: 0.019)\n",
      "Parameters: {'validation_fraction': 0.2, 'subsample': 0.6, 'n_iter_no_change': 5, 'n_estimators': 500, 'max_depth': 4, 'loss': 'log_loss', 'learning_rate': 0.01}\n",
      "\n",
      "Model with rank: 4\n",
      "Mean validation score: 0.828 (std: 0.031)\n",
      "Parameters: {'validation_fraction': 0.2, 'subsample': 0.8, 'n_iter_no_change': 5, 'n_estimators': 100, 'max_depth': 5, 'loss': 'log_loss', 'learning_rate': 0.03}\n",
      "\n",
      "Model with rank: 5\n",
      "Mean validation score: 0.826 (std: 0.038)\n",
      "Parameters: {'validation_fraction': 0.2, 'subsample': 0.8, 'n_iter_no_change': 5, 'n_estimators': 100, 'max_depth': 4, 'loss': 'log_loss', 'learning_rate': 0.01}\n",
      "\n",
      "Model with rank: 6\n",
      "Mean validation score: 0.826 (std: 0.025)\n",
      "Parameters: {'validation_fraction': 0.2, 'subsample': 1, 'n_iter_no_change': 5, 'n_estimators': 300, 'max_depth': 3, 'loss': 'log_loss', 'learning_rate': 0.05}\n",
      "\n",
      "Model with rank: 7\n",
      "Mean validation score: 0.825 (std: 0.026)\n",
      "Parameters: {'validation_fraction': 0.2, 'subsample': 0.8, 'n_iter_no_change': 5, 'n_estimators': 500, 'max_depth': 4, 'loss': 'log_loss', 'learning_rate': 0.01}\n",
      "\n",
      "Model with rank: 8\n",
      "Mean validation score: 0.825 (std: 0.035)\n",
      "Parameters: {'validation_fraction': 0.2, 'subsample': 1, 'n_iter_no_change': 5, 'n_estimators': 500, 'max_depth': 3, 'loss': 'log_loss', 'learning_rate': 0.03}\n",
      "\n",
      "Model with rank: 9\n",
      "Mean validation score: 0.824 (std: 0.034)\n",
      "Parameters: {'validation_fraction': 0.2, 'subsample': 0.6, 'n_iter_no_change': 5, 'n_estimators': 100, 'max_depth': 4, 'loss': 'log_loss', 'learning_rate': 0.03}\n",
      "\n",
      "Model with rank: 10\n",
      "Mean validation score: 0.824 (std: 0.032)\n",
      "Parameters: {'validation_fraction': 0.2, 'subsample': 0.6, 'n_iter_no_change': 5, 'n_estimators': 100, 'max_depth': 5, 'loss': 'log_loss', 'learning_rate': 0.01}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "search = RandomizedSearchCV(\n",
    "    estimator=model,\n",
    "    param_distributions=params,\n",
    "    scoring=score,\n",
    "    cv=cv,\n",
    "    n_iter=n_iter,\n",
    "    return_train_score=False,\n",
    "    refit=True\n",
    ")\n",
    "\n",
    "# fit\n",
    "start = time()\n",
    "search.fit(X, y)\n",
    "\n",
    "# save\n",
    "save_obj(search.best_estimator_, os.path.join(workdir, exp_prefix, 'artifacts', 'tunned_model.pkl'))\n",
    "\n",
    "# report\n",
    "print(\n",
    "    \"Tunning took %.2f seconds for %d candidate parameter settings.\"\n",
    "    % (time() - start, len(search.cv_results_[\"params\"]))\n",
    ")\n",
    "\n",
    "print('###')\n",
    "\n",
    "report(search.cv_results_, n_top=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('new-titan')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "353d4c0fb3a2b2a782e8651e9160ee5f7d61a2371621a296956cde93287d73c8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
