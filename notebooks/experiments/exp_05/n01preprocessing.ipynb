{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "from numpy import savetxt\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project\n",
    "workdir = '/home/walter/Documents/personal_projects/new-titan'\n",
    "exp_prefix = 'notebooks/experiments/exp_04'\n",
    "data_prefix = 'data'\n",
    "chk_prefix = 'checkpoint'\n",
    "\n",
    "# Params\n",
    "target = 'Survived'\n",
    "features = ['Sex', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked', 'Name', 'Ticket']\n",
    "idx = 'Passengerid'\n",
    "\n",
    "# Paths \n",
    "data_train_path = os.path.join(workdir, data_prefix, 'raw/train.csv')\n",
    "\n",
    "dict_path = os.path.join(workdir, exp_prefix, chk_prefix, 'train_dict.pkl')\n",
    "\n",
    "# Text Replacement\n",
    "app_origin = ['Mr',\n",
    " 'Mrs',\n",
    " 'Miss',\n",
    " 'Master',\n",
    " 'Don',\n",
    " 'Rev',\n",
    " 'Dr',\n",
    " 'Mme',\n",
    " 'Ms',\n",
    " 'Major',\n",
    " 'Mrs. Martin (Elizabeth L',\n",
    " 'Lady',\n",
    " 'Sir',\n",
    " 'Mlle',\n",
    " 'Col',\n",
    " 'Capt',\n",
    " 'the Countess',\n",
    " 'Jonkheer',\n",
    " 'other']\n",
    "\n",
    "replacements = ['Mr', 'Mrs', 'Miss', 'Master', 'Mr', 'Rev', 'Dr', 'Mrs', 'Mrs', 'other',\n",
    " 'Mrs', 'Miss', 'Mr', 'Miss', 'other', \n",
    " 'other', 'other', 'other', 'other']\n",
    "\n",
    "replace_app = dict(zip(app_origin, replacements))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_for_eval(df, test_size):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df[features], df[target], test_size=test_size, random_state=100)\n",
    "    label_train = df.iloc[X_train.index, 0]\n",
    "    label_test = df.iloc[X_test.index, 0]\n",
    "    return X_train, y_train, label_train, X_test, y_test, label_test\n",
    "\n",
    "def save_obj(obj, path):\n",
    "    if not os.path.exists(os.path.split(path)[0]):\n",
    "        os.mkdir(os.path.split(path)[0])\n",
    "\n",
    "    file = open(path, 'wb')\n",
    "    pickle.dump(obj, file)\n",
    "    file.close()\n",
    "\n",
    "def load_obj(path):\n",
    "    file = open(path, 'rb')\n",
    "    obj = pickle.load(file)\n",
    "    file.close()\n",
    "    return obj\n",
    "\n",
    "def train_imputers(df, path):\n",
    "    dict = defaultdict(None)\n",
    "    dict['embarked_mode'] = df['Embarked'].mode().values[0]\n",
    "    dict['age_mean'] = df['Age'].mean()\n",
    "    dict['fare_mean'] = df['Fare'].mean()\n",
    "    save_obj(dict, path)\n",
    "    print('> Trained imputers.')\n",
    "\n",
    "def apply_imputers(df, path):\n",
    "    dict = load_obj(path)\n",
    "    data = df\n",
    "    data['Age'] = data['Age'].fillna(dict['age_mean'])\n",
    "    data['Embarked'] = data['Embarked'].fillna(dict['embarked_mode'])\n",
    "    data['Fare'] = data['Fare'].fillna(dict['fare_mean'])\n",
    "    print('> Applied imputers.')\n",
    "    return data\n",
    "\n",
    "def train_pclass_encoder(df, path):\n",
    "    enc = OneHotEncoder(sparse=False, handle_unknown='infrequent_if_exist')\n",
    "    enc.fit(df[['Pclass']])\n",
    "    save_obj(enc, path)\n",
    "\n",
    "def train_embarked_encoder(df, path):\n",
    "    enc = OneHotEncoder(sparse=False, handle_unknown='infrequent_if_exist')\n",
    "    enc.fit(df[['Embarked']])\n",
    "    save_obj(enc, path)\n",
    "\n",
    "def train_sex_encoder(df, path):\n",
    "    enc = LabelEncoder()\n",
    "    enc.fit(df['Sex'])\n",
    "    save_obj(enc, path)\n",
    "\n",
    "def prep_fam_size(df):\n",
    "    data = df\n",
    "    ranges = [-1,0,1,3,1000]\n",
    "    data['fam_size'] = pd.cut((data['SibSp'] + data['Parch']), ranges, labels=['0', '1', '2', '3'])\n",
    "    data['fam_size'] = data['fam_size'].astype('float')\n",
    "    return data\n",
    "\n",
    "def train_encoders(df, path):\n",
    "    train_pclass_encoder(df, os.path.join(path, 'pclass_encoder.pkl'))\n",
    "    train_embarked_encoder(df, os.path.join(path, 'embarked_encoder.pkl'))\n",
    "    train_sex_encoder(df, os.path.join(path, 'sex_encoder.pkl'))\n",
    "    print('> Trained encoders.')\n",
    "\n",
    "def train_process_name(df, path):\n",
    "\n",
    "    app_origin = ['Mr',\n",
    "        'Mrs',\n",
    "        'Miss',\n",
    "        'Master',\n",
    "        'Don',\n",
    "        'Rev',\n",
    "        'Dr',\n",
    "        'Mme',\n",
    "        'Ms',\n",
    "        'Major',\n",
    "        'Mrs. Martin (Elizabeth L',\n",
    "        'Lady',\n",
    "        'Sir',\n",
    "        'Mlle',\n",
    "        'Col',\n",
    "        'Capt',\n",
    "        'the Countess',\n",
    "        'Jonkheer',\n",
    "        'other']\n",
    "\n",
    "    replacements = ['Mr', 'Mrs', 'Miss', 'Master', 'Mr', 'Rev', 'Dr', 'Mrs', 'Mrs', 'other',\n",
    "    'Mrs', 'Miss', 'Mr', 'Miss', 'other', \n",
    "    'other', 'other', 'other', 'other']\n",
    "\n",
    "    replace_app = dict(zip(app_origin, replacements))\n",
    "\n",
    "    data = df\n",
    "    data['ntitle'] = [re.search(r',.+\\.', name).group()[2:-1] for name in data['Name']]\n",
    "    data.loc[~(data['ntitle'].isin(app_origin)), 'ntitle'] = 'other'\n",
    "    data = data.replace({'ntitle':replace_app})\n",
    "    enc = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "    enc.fit(data[['ntitle']])\n",
    "    save_obj(enc, path)\n",
    "\n",
    "def add_count_col(df, col, new_col_name):\n",
    "    counter = df[col].value_counts()\n",
    "    counter = pd.DataFrame({col: counter.index, new_col_name: counter}).reset_index(drop=True)\n",
    "    df_with_col = pd.merge(df, counter, on=col, how='left')\n",
    "    return df_with_col\n",
    "\n",
    "def train_count_tickets(df, path):\n",
    "    data = df\n",
    "    data = add_count_col(data, 'Ticket', 'Ticket_counter')\n",
    "    table_count_tickets = data[['Ticket', 'Ticket_counter']].drop_duplicates()\n",
    "    table_count_tickets.to_csv(path, index=False, header=True)\n",
    "    data = data.drop('Ticket', axis=1)\n",
    "    return data\n",
    "\n",
    "def apply_sex_encoder(df, path):\n",
    "    enc = load_obj(path)\n",
    "    res = enc.transform(df['Sex'])\n",
    "    df['Sex'] = res\n",
    "    return df\n",
    "\n",
    "def apply_pclass_encoder(df, path):\n",
    "    enc = load_obj(path)\n",
    "    new_cols = ['Pclass_' + str(c) for c in enc.categories_[0]]\n",
    "    data = df\n",
    "    data[new_cols] = enc.transform(data[['Pclass']])\n",
    "    data = data.drop(['Pclass'], axis=1)\n",
    "    return data\n",
    "\n",
    "def apply_embarked_encoder(df, path):\n",
    "    enc = load_obj(path)\n",
    "    new_cols = ['Embarked_' + str(c) for c in enc.categories_[0]]\n",
    "    data = df\n",
    "    data[new_cols] = enc.transform(data[['Embarked']])\n",
    "    data = data.drop(['Embarked'], axis=1)\n",
    "    return data\n",
    "\n",
    "def apply_encoders(df, path):\n",
    "    res = apply_pclass_encoder(df, os.path.join(path, 'pclass_encoder.pkl'))\n",
    "    res = apply_embarked_encoder(res, os.path.join(path, 'embarked_encoder.pkl'))\n",
    "    res = apply_sex_encoder(res , os.path.join(path, 'sex_encoder.pkl'))\n",
    "    print('> Applied encoders.')\n",
    "    return res\n",
    "\n",
    "def apply_process_name(df, path):\n",
    "\n",
    "    app_origin = ['Mr',\n",
    "    'Mrs',\n",
    "    'Miss',\n",
    "    'Master',\n",
    "    'Don',\n",
    "    'Rev',\n",
    "    'Dr',\n",
    "    'Mme',\n",
    "    'Ms',\n",
    "    'Major',\n",
    "    'Mrs. Martin (Elizabeth L',\n",
    "    'Lady',\n",
    "    'Sir',\n",
    "    'Mlle',\n",
    "    'Col',\n",
    "    'Capt',\n",
    "    'the Countess',\n",
    "    'Jonkheer',\n",
    "    'other']\n",
    "\n",
    "    replacements = ['Mr', 'Mrs', 'Miss', 'Master', 'Mr', 'Rev', 'Dr', 'Mrs', 'Mrs', 'other',\n",
    "    'Mrs', 'Miss', 'Mr', 'Miss', 'other', \n",
    "    'other', 'other', 'other', 'other']\n",
    "\n",
    "    replace_app = dict(zip(app_origin, replacements))\n",
    "\n",
    "    enc = load_obj(path)\n",
    "    new_cols = ['ntitle_' + str(c) for c in enc.categories_[0]]\n",
    "    data = df\n",
    "    data['ntitle'] = [re.search(r',.+\\.', name).group()[2:-1] for name in data['Name']]\n",
    "    data.loc[~(data['ntitle'].isin(app_origin)), 'ntitle'] = 'other'\n",
    "    data = data.replace({'ntitle':replace_app})\n",
    "    data[new_cols] = enc.transform(data[['ntitle']])\n",
    "    data = data.drop(['ntitle', 'Name'], axis=1)\n",
    "    return data\n",
    "\n",
    "def train_count_tickets(df, path):\n",
    "    data = df\n",
    "    data = add_count_col(data, 'Ticket', 'Ticket_counter')\n",
    "    table_count_tickets = data[['Ticket', 'Ticket_counter']].drop_duplicates()\n",
    "    table_count_tickets.to_csv(os.path.join(path), index=False, header=True)\n",
    "    data = data.drop('Ticket', axis=1)\n",
    "    return data\n",
    "\n",
    "def apply_count_tickets(df, path):\n",
    "    table_count_tickets = pd.read_csv(path)\n",
    "    data = df\n",
    "    data = add_count_col(data, 'Ticket', 'Ticket_counter')\n",
    "    data = pd.merge(data, table_count_tickets, on='Ticket', how='left')\n",
    "    data['Ticket_counter_y'] = data['Ticket_counter_y'].fillna(0)\n",
    "    data['Ticket_counter'] = data['Ticket_counter_x'] + data['Ticket_counter_y'] \n",
    "    data = data.drop(['Ticket_counter_x', 'Ticket_counter_y', 'Ticket'], axis = 1)\n",
    "    return data\n",
    "\n",
    "def process_train(X_train, path):\n",
    "    train_imputers(X_train, os.path.join(path, 'train_dict.pkl'))\n",
    "    res = apply_imputers(X_train, os.path.join(path, 'train_dict.pkl'))\n",
    "    train_encoders(res, path)\n",
    "    res = apply_encoders(res, path)\n",
    "    train_process_name(res, os.path.join(path, 'process_name_enc.pkl'))\n",
    "    res = apply_process_name(res, os.path.join(path, 'process_name_enc.pkl'))\n",
    "    res = train_count_tickets(res, os.path.join(path, 'table_count_tickets.csv'))\n",
    "    res = prep_fam_size(res)\n",
    "    return res\n",
    "\n",
    "def apply_transform(df, path):\n",
    "    res = apply_imputers(df, os.path.join(path, 'train_dict.pkl'))\n",
    "    res = apply_encoders(res, path)\n",
    "    res = apply_process_name(res, os.path.join(path, 'process_name_enc.pkl'))\n",
    "    res = apply_count_tickets(res, os.path.join(path, 'table_count_tickets.csv'))\n",
    "    res = prep_fam_size(res)\n",
    "    return res\n",
    "\n",
    "def save_train_files(path):\n",
    "    savetxt(os.path.join(path, 'data_train', 'X_train.csv'), X_train_processed, delimiter=',')\n",
    "    savetxt(os.path.join(path, 'data_train', 'y_train.csv'), y_train, delimiter=',')\n",
    "    savetxt(os.path.join(path, 'data_train', 'label_train.csv'), label_train, delimiter=',')\n",
    "    savetxt(os.path.join(path, 'data_test', 'X_test.csv'), X_test_processed, delimiter=',')\n",
    "    savetxt(os.path.join(path, 'data_test', 'y_test.csv'), y_test, delimiter=',')\n",
    "    savetxt(os.path.join(path, 'data_test', 'label_test.csv'), label_test, delimiter=',')\n",
    "    print(f'X_train saved in: {os.path.join(path, \"X_train.csv\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Trained imputers.\n",
      "> Applied imputers.\n",
      "> Trained encoders.\n",
      "> Applied encoders.\n",
      "> Applied imputers.\n",
      "> Applied encoders.\n",
      "X_train saved in: /home/walter/Documents/personal_projects/new-titan/data/processed/X_train.csv\n"
     ]
    }
   ],
   "source": [
    "# Load\n",
    "data = pd.read_csv(os.path.join(workdir, data_prefix, 'raw/train.csv'), header=0)\n",
    "\n",
    "# Create datasets for eval\n",
    "X_train, y_train, label_train, X_test, y_test, label_test = split_for_eval(data, 0.1)\n",
    "\n",
    "# Process X_train\n",
    "X_train_processed = process_train(X_train, os.path.join(workdir, exp_prefix, chk_prefix))\n",
    "X_test_processed = apply_transform(X_test, os.path.join(workdir, exp_prefix, chk_prefix))\n",
    "\n",
    "# Save\n",
    "save_train_files(os.path.join(workdir, data_prefix, 'processed'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(801, 20)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_processed.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('new-titan')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "353d4c0fb3a2b2a782e8651e9160ee5f7d61a2371621a296956cde93287d73c8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
