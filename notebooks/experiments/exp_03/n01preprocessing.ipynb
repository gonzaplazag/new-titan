{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from numpy import savetxt\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project\n",
    "workdir = '/home/walter/Documents/personal_projects/new-titan'\n",
    "exp_prefix = 'notebooks/experiments/exp_03'\n",
    "data_prefix = 'data'\n",
    "chk_prefix = 'checkpoint'\n",
    "\n",
    "# Params\n",
    "target = 'Survived'\n",
    "features = ['Sex', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']\n",
    "idx = 'Passengerid'\n",
    "\n",
    "# Paths \n",
    "data_train_path = os.path.join(workdir, data_prefix, 'raw/train.csv')\n",
    "\n",
    "dict_path = os.path.join(workdir, exp_prefix, chk_prefix, 'train_dict.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_for_eval(df, test_size):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df[features], df[target], test_size=test_size, random_state=100)\n",
    "    label_train = df.iloc[X_train.index, 0]\n",
    "    label_test = df.iloc[X_test.index, 0]\n",
    "    return X_train, y_train, label_train, X_test, y_test, label_test\n",
    "\n",
    "def save_obj(obj, path):\n",
    "    if not os.path.exists(os.path.split(path)[0]):\n",
    "        os.mkdir(os.path.split(path)[0])\n",
    "\n",
    "    file = open(path, 'wb')\n",
    "    pickle.dump(obj, file)\n",
    "    file.close()\n",
    "\n",
    "def load_obj(path):\n",
    "    file = open(path, 'rb')\n",
    "    obj = pickle.load(file)\n",
    "    file.close()\n",
    "    return obj\n",
    "\n",
    "def train_imputers(df, path):\n",
    "    dict = defaultdict(None)\n",
    "    dict['embarked_mode'] = df['Embarked'].mode().values[0]\n",
    "    dict['age_mean'] = df['Age'].mean()\n",
    "    dict['fare_mean'] = df['Fare'].mean()\n",
    "    save_obj(dict, path)\n",
    "    print('> Trained imputers.')\n",
    "\n",
    "def apply_imputers(df, path):\n",
    "    dict = load_obj(path)\n",
    "    data = df\n",
    "    data['Age'] = data['Age'].fillna(dict['age_mean'])\n",
    "    data['Embarked'] = data['Embarked'].fillna(dict['embarked_mode'])\n",
    "    data['Fare'] = data['Fare'].fillna(dict['fare_mean'])\n",
    "    print('> Applied imputers.')\n",
    "    return data\n",
    "\n",
    "def train_pclass_encoder(df, path):\n",
    "    enc = OneHotEncoder(sparse=False, handle_unknown='infrequent_if_exist')\n",
    "    enc.fit(df[['Pclass']])\n",
    "    save_obj(enc, path)\n",
    "\n",
    "def train_embarked_encoder(df, path):\n",
    "    enc = OneHotEncoder(sparse=False, handle_unknown='infrequent_if_exist')\n",
    "    enc.fit(df[['Embarked']])\n",
    "    save_obj(enc, path)\n",
    "\n",
    "def train_sex_encoder(df, path):\n",
    "    enc = LabelEncoder()\n",
    "    enc.fit(df['Sex'])\n",
    "    save_obj(enc, path)\n",
    "\n",
    "def train_encoders(df, path):\n",
    "    train_pclass_encoder(df, os.path.join(path, 'pclass_encoder.pkl'))\n",
    "    train_embarked_encoder(df, os.path.join(path, 'embarked_encoder.pkl'))\n",
    "    train_sex_encoder(df, os.path.join(path, 'sex_encoder.pkl'))\n",
    "    print('> Trained encoders.')\n",
    "\n",
    "def apply_sex_encoder(df, path):\n",
    "    enc = load_obj(path)\n",
    "    res = enc.transform(df['Sex'])\n",
    "    df['Sex'] = res\n",
    "    return df\n",
    "\n",
    "def apply_pclass_encoder(df, path):\n",
    "    enc = load_obj(path)\n",
    "    new_cols = ['Pclass_' + str(c) for c in enc.categories_[0]]\n",
    "    data = df\n",
    "    data[new_cols] = enc.transform(data[['Pclass']])\n",
    "    data = data.drop(['Pclass'], axis=1)\n",
    "    return data\n",
    "\n",
    "def apply_embarked_encoder(df, path):\n",
    "    enc = load_obj(path)\n",
    "    new_cols = ['Embarked_' + str(c) for c in enc.categories_[0]]\n",
    "    data = df\n",
    "    data[new_cols] = enc.transform(data[['Embarked']])\n",
    "    data = data.drop(['Embarked'], axis=1)\n",
    "    return data\n",
    "\n",
    "def apply_encoders(df, path):\n",
    "    res = apply_pclass_encoder(df, os.path.join(path, 'pclass_encoder.pkl'))\n",
    "    res = apply_embarked_encoder(res, os.path.join(path, 'embarked_encoder.pkl'))\n",
    "    res = apply_sex_encoder(res , os.path.join(path, 'sex_encoder.pkl'))\n",
    "    print('> Applied encoders.')\n",
    "    return res\n",
    "\n",
    "def process_train(X_train, path):\n",
    "    train_imputers(X_train, os.path.join(path, 'train_dict.pkl'))\n",
    "    res = apply_imputers(X_train, os.path.join(path, 'train_dict.pkl'))\n",
    "    train_encoders(res, path)\n",
    "    res = apply_encoders(res, path)\n",
    "    return res.values\n",
    "\n",
    "def apply_transform(df, path):\n",
    "    res = apply_imputers(df, os.path.join(path, 'train_dict.pkl'))\n",
    "    res = apply_encoders(res, path)\n",
    "    return res.values\n",
    "\n",
    "def save_train_files(path):\n",
    "    savetxt(os.path.join(path, 'X_train.csv'), X_train_processed, delimiter=',')\n",
    "    savetxt(os.path.join(path, 'y_train.csv'), y_train, delimiter=',')\n",
    "    savetxt(os.path.join(path, 'label_train.csv'), label_train, delimiter=',')\n",
    "    savetxt(os.path.join(path, 'X_test.csv'), X_test_processed, delimiter=',')\n",
    "    savetxt(os.path.join(path, 'y_test.csv'), y_test, delimiter=',')\n",
    "    savetxt(os.path.join(path, 'label_test.csv'), label_test, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Trained imputers.\n",
      "> Applied imputers.\n",
      "> Trained encoders.\n",
      "> Applied encoders.\n",
      "> Applied imputers.\n",
      "> Applied encoders.\n"
     ]
    }
   ],
   "source": [
    "# Load\n",
    "data = pd.read_csv(os.path.join(workdir, data_prefix, 'raw/train.csv'), header=0)\n",
    "\n",
    "# Create datasets for eval\n",
    "X_train, y_train, label_train, X_test, y_test, label_test = split_for_eval(data, 0.1)\n",
    "\n",
    "# Process X_train\n",
    "X_train_processed = process_train(X_train, os.path.join(workdir, exp_prefix, chk_prefix))\n",
    "X_test_processed = apply_transform(X_test, os.path.join(workdir, exp_prefix, chk_prefix))\n",
    "\n",
    "# Save\n",
    "save_train_files(os.path.join(workdir, data_prefix, 'processed'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('new-titan')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "353d4c0fb3a2b2a782e8651e9160ee5f7d61a2371621a296956cde93287d73c8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
