{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Trained imputers.\n",
      "> Applied imputers.\n",
      "> Trained encoders.\n",
      "> Applied encoders.\n",
      "> Applied imputers.\n",
      "> Applied encoders.\n",
      "X_train saved in: /home/walter/Documents/personal_projects/new-titan/data/processed/X_train.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from ipynb.fs.full.n01preprocessing import save_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project\n",
    "workdir = '/home/walter/Documents/personal_projects/new-titan'\n",
    "exp_prefix = 'notebooks/experiments/exp_04'\n",
    "data_prefix = 'data'\n",
    "chk_prefix = 'checkpoint'\n",
    "\n",
    "# Params\n",
    "target = 'Survived'\n",
    "features = ['Sex', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked', 'Name', 'Ticket']\n",
    "idx = 'Passengerid'\n",
    "\n",
    "# Paths \n",
    "data_train_path = os.path.join(workdir, data_prefix, 'raw/train.csv')\n",
    "\n",
    "dict_path = os.path.join(workdir, exp_prefix, chk_prefix, 'train_dict.pkl')\n",
    "\n",
    "# Text Replacement\n",
    "app_origin = ['Mr',\n",
    " 'Mrs',\n",
    " 'Miss',\n",
    " 'Master',\n",
    " 'Don',\n",
    " 'Rev',\n",
    " 'Dr',\n",
    " 'Mme',\n",
    " 'Ms',\n",
    " 'Major',\n",
    " 'Mrs. Martin (Elizabeth L',\n",
    " 'Lady',\n",
    " 'Sir',\n",
    " 'Mlle',\n",
    " 'Col',\n",
    " 'Capt',\n",
    " 'the Countess',\n",
    " 'Jonkheer',\n",
    " 'other']\n",
    "\n",
    "replacements = ['Mr', 'Mrs', 'Miss', 'Master', 'Mr', 'Rev', 'Dr', 'Mrs', 'Mrs', 'other',\n",
    " 'Mrs', 'Miss', 'Mr', 'Miss', 'other', \n",
    " 'other', 'other', 'other', 'other']\n",
    "\n",
    "replace_app = dict(zip(app_origin, replacements))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models to test\n",
    "models = [\n",
    "    DecisionTreeClassifier(random_state = 2),\n",
    "    LogisticRegression(random_state=2, max_iter=1000),\n",
    "    RandomForestClassifier(random_state=0),\n",
    "    GradientBoostingClassifier()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(prefix):\n",
    "    X_train = np.genfromtxt(os.path.join(prefix, 'data_train', 'X_train.csv'), delimiter=',')\n",
    "    y_train = np.genfromtxt(os.path.join(prefix, 'data_train', 'y_train.csv'), delimiter=',').astype('int')\n",
    "    label_train = np.genfromtxt(os.path.join(prefix, 'data_train', 'label_train.csv'), delimiter=',')\n",
    "   \n",
    "    return X_train, y_train, label_train\n",
    "\n",
    "def eval_model(X, y, model):\n",
    "    k = 5\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=2)\n",
    "\n",
    "    acc_score = []\n",
    "\n",
    "    for train_index, valid_index in kf.split(X):\n",
    "\n",
    "        # load\n",
    "        X_train, X_valid = X[train_index], X[valid_index]\n",
    "        y_train, y_valid = y[train_index], y[valid_index]\n",
    "\n",
    "        # model\n",
    "        model.fit(X_train, y_train)\n",
    "        y_predict = model.predict(X_valid)\n",
    "\n",
    "        # eval\n",
    "        acc = accuracy_score(y_predict, y_valid)\n",
    "        acc_score.append(acc)\n",
    "\n",
    "    avg_acc_score = sum(acc_score)/k\n",
    "    return avg_acc_score  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/walter/Documents/personal_projects/new-titan/data/processed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(801, 20)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y, label = load_data(os.path.join(workdir, data_prefix, 'processed'))\n",
    "print(os.path.join(workdir, data_prefix, 'processed'))\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7953027950310559, 0.8227484472049689, 0.8052717391304348, 0.8264751552795031]\n",
      "GradientBoostingClassifier()\n"
     ]
    }
   ],
   "source": [
    "# Load\n",
    "X, y, label = load_data(os.path.join(workdir, data_prefix, 'processed'))\n",
    "\n",
    "# Eval\n",
    "res_eval = [eval_model(X, y, model) for model in models]\n",
    "\n",
    "# save selected model\n",
    "selected_model = models[res_eval.index(max(res_eval))]\n",
    "save_obj(selected_model, os.path.join(workdir, exp_prefix, 'artifacts', 'selected_model.pkl'))\n",
    "\n",
    "print(res_eval)\n",
    "print(selected_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('new-titan')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "353d4c0fb3a2b2a782e8651e9160ee5f7d61a2371621a296956cde93287d73c8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
